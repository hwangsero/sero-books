---
description: 참고문헌 - 실전 카프카 개발에서 운영까지
---

# Kafka 정리

실시간 로그 수집 프로세스를 구축하기 위해서 데이터를 안정적으로 버퍼링하고 전달할 수 있도록 하는 중간 메시지 큐가 필요로 했습니다. 이러한 메시지 전송 플랫폼으로 kafka에 대해 공부해보고 간단한 실습을 해보고자 합니다.

### Kafka

**kafka**는 높은 처리량을 바탕으로 실시간 스트리밍 데이터를 처리하기 위한 분산 데이터 스트리밍 메시지 플랫폼입니다. pub/sub 모델을 기반으로 topic을 구독해서 발행받는 방식을 기반으로 구현되어 있습니다. 아직까지는 일반적으로 메타데이터를 관리해주는 주키퍼와 함께 사용되며 분산 시스템을 통해 안정성과 높은 처리량 등을 지원하는 메시지 플랫폼입니다.

### Why Kafka?

수 많은 기업들이 카프카의 어떤 장점들 때문에 사용하지는 카프카의 주요 특성들에 대해 알아보겠습니다.

**높은 처리량과 낮은 지연시간**

카프카는 매우 높은 처리량과 낮은 지연시간을 자랑합니다. 기업들은 예측할 수 없이 늘어나는 데이터들을 처리하기 위해 처리량은 높은 시스템을 선호합니다. 카프카는 펄사 메시징 시스템, 래빗MQ와 비교해도 가장 높은 처리량과 낮은 지연시간을 제공합니다.

**높은 확장성**

아무리 처리량이 높은 시스템이라 할지라도 분명 그 끝은 존재합니다. 그렇기 때문에 예측할 수 없이 늘어나는 데이터들을 처리하기 위해서는 확장이 가능해야합니다. 카프카는 손쉬운 확장이 가능하도록 클러스터를 구성할 수 있게 설계된 애플리케이션입니다.

**고가용성**

카프카는 리플리케이션을 통해 메시지를 여러 브로커에 중복으로 보관함으로써 고가용성을 갖추었습니다. 리플리케이션에 대해서는 아래에서 자세히 살펴보겠습니다.

**내구성**

카프카는 프로듀서의 acks라는 옵션을 조정하여 메시지의 내구성을 강화할 수 있습니다. 또한 프로듀서에 의해 카프카로 전송되는 모든 메시지는 안전한 저장소인 카프카의 로컬 디스크에 저장됩니다.

### 카프카 기본 개념과 구조

#### 기본 용어

> **주키퍼**: 카프카의 메타데이터 관리 및 브로커의 정상상태 점검(health check)을 담당한다.\
> **브로커**: 카프카 애플리케이션이 설치된 서버 또는 노드\
> **프로듀서**: 카프카로 메시지를 보내는 역할을 하는 클라이언트\
> **컨슈머**: 카프카에서 메시지를 꺼내가는 역할을 하는 클라이언트\
> **파티션**: 병렬 처리 및 고성능을 얻기 위해 하나의 토픽을 여러 개로 나눈 것\
> **세그먼트**: 프로듀서가 전송한 실제 메시지가 브로커의 로컬 디스크에 저장되는 파일

#### 리플리케이션

카프카에서 **리플리케이션**이란 각 메시지들을 여러 개로 복제해서 카프카 클러스터내 브로커들에 분산시키는 동작을 의미합니다. 정확하게는 카프카에서 토픽이 리플리케이션 되는게 아니라 토픽의 파티션이 리플리케이션되는 것입니다.

```
--replication-factor 3
```

다음과 같이 토픽을 생성할 때 리플리케이션 갯수를 설정할 수 있습니다. 리플리케이션 팩터 수가 3으로 설정하면 원본을 포함한 리플리케이션이 총 3개가 있다는 뜻입니다.

리플리케이션 팩터 수가 커지면 안정성은 높아지지만 그만큼 브로커 리소스를 많이 사용하게 되기 때문에 적절한 수로 설정하는 것이 좋습니다.

#### 파티션

하나의 토픽이 한 번에 처리할 수 있는 한계를 높이기 위해 토픽 하나를 여러 개로 나눠 병렬 처리가 가능하게 만든 것을 **파티션**이라고 합니다. 이렇게 나뉜 파티션 수만큼 컨슈머를 연결할 수 있기 때문에 분산 처리가 가능하게 됩니다.

특히 파티션 수는 초기 생성 후 언제든지 늘릴 수 있지만, **한 번 늘린 파티션 수는 절대로 줄일 수 없다는 점**을 명심해야합니다. 따라서 초기에 토픽을 생성할 때 파티션 수를 작게 생성한 후, 메시지 처리량이나 컨슈머의 LAG 등을 모니터링하면서 조금씩 늘려가는 방법이 가장 좋습니다.

#### 세그먼트

프로듀서에 의해 브로커로 전송된 메시지는 토픽의 파티션에 저장되며, 각 메시지들은 세그먼트라는 로그 파일의 형태로 브로커의 로컬 디스크에 저장됩니다.

```
00000000000000000000.log 00000000000000000000.index 00000000000000000000.timeindex
```

세그먼트 파일들은 다음과 같은 형태로 디스크에 저장되는데 hexdump를 보여주는 xxd 명령어를 이용해 00000000000000000000.log안의 내용을 확인할 수 있습니다.

```
xxd 00000000000000000000.log

--결과 예시--
000cae00: 2669 763d 3230 2e31 3030 372e 3030 2661  &iv=00.0000.00&a
000cae10: 665f 6964 3d31 3630 3232 3732 3331 3832  f_id=1111111111
000cae20: 3833 2d35 3238 3237 3331 2663 3d26 6166  1111111111&c=&af
000cae30: 5f73 6974 6569 643d 266d 6564 6961 5f73  _siteid=&media_s
000cae40: 6f75 7263 653d 2661 665f 6b65 7977 6f72  ource=&af_keywor
000cae50: 6473 3d26 6167 7265 6564 5f61 645f 7461  ds=&aaaa_ad_ta^Z
```

kafka-dump-log.sh 스크립트를 사용하면 보기 편한 형태로 세그먼트 파일을 상세히 확인할 수 있습니다.

```
kafka-dump-log.sh 00000000000000000000.log

-- 결과 예시
| offset: 14812561 CreateTime: 1664436149642 keySize: -1 valueSize: 793 sequence: 1971 headerKeys: [] payload: 2022-09-07T00:21:22+09:00		{"remote":"95.148.223.81","host":"-","user":"-","method":"GET","path":"https://fastlog.bitmango.com/?event=AEO_PTIME&logdate=2022-09-06+15%3a21%3a20+GMT&a=lollipop2match3&b=com.bitmango.go.lollipop2match3&vid=a1ab8efaa8cfb8e0590860e5ff18afd1&v=22.0818.01&dv=22.0818.01.MASTER&s=ANDROID&o=Android+OS+11+%2f+API-30+(RP1A.200720.012%2fT515XXU8CVG2)&d=samsung+SM-T515&it=2022-04-21+19%3a05%3a13+GMT&iv=22.0418.09.MASTER&af_id=1650567936660-7422655008747573299&c=com.bitmango.go.lollipop2match3-facebook-gb-reward_max-aaa-yd&af_siteid=&media_source=Facebook+Ads&af_keywords=&agreed_ad_targeting=True&agreed_tos=True&v1=4710","code":"200","size":"0","referer":"-","agent":"UnityPlayer/2020.3.26f1 (UnityWebRequest/1.0, libcurl/7.77.0-DEV)","http_x_forwarded_for":"0.001"}
```

**세그먼트 관리**

로그 세그먼트에는 메시지의 내용만 저장되는 것이 아니라 메시지의 키, 밸류, 오프셋, 메시지 크기와 같은 정보가 함께 저장됩니다. 로그 세그먼트의 최대 크기는 1GB가 기본값으로 설정되어 있어 1GB보다 커지면 새로운 로그 세그먼트파일을 생성하여 내용을 저장합니다. 이러한 1GB의 로그 세그먼트가 무한히 늘어날 경우를 대비해 로그 세그먼트에 대한 관리 계획을 수립해야하는데 크게 로그 세그먼트 삭제와 컴팩션으로 구분할 수 있습니다.

**로그 세그먼트 삭제**

특정 주기동안 특정 시간 보다 오래된 로그 세그먼트 파일을 삭제하는 방식을 사용할 수 있습니다.

**로그 세그먼트 컴팩션**

로그를 삭제하지 않고 컴팩션하여 보관할 수 있습니다. 현재 활성화된 세그먼트는 제외하고 나머지 세그먼트들을 대상으로 컴팩션이 실행됩니다. 카프카에서는 단순하게 메시지를 컴팩션하여 보관하기보다는 좀 더 효율적인 방법으로 컴팩션합니다. 카프카에서 로그 세그먼트를 컴팩션하면 메시지의 키값을 기준으로 마지막의 데이터만 보관하게 됩니다. 로그 컴팩션은 메시지의 키값을 기준으로 과거 정보는 중요하지 않고 가장 마지막 값이 필요한 경우에 사용합니다. 카프카로 메시지를 전송할 때, 메시지에는 메시지의 키와 밸류를 같이 전송하게 되는데 밸류는 필숫값이지만 키는 필숫값이 아닙니다. 따라서 로그 컴팩션 기능을 사용하고자 한다면, 카프카로 메시지를 전송할 때 키도 필숫값으로 전송해야 합니다.

로그 컴팩션의 장점은 빠른 장애 복구입니다. 장애 복구 시 전체 로그를 복구하지 않고, 메시지의 키를 기준으로 최신의 상태만 복구합니다. 하지만 빠른 재처리라는 장점이 있다고 해서 모든 토픽에 로그 컴팩션을 적용하는 것은 좋지 않습니다. **키값을 기준으로 최종값만 필요한 워크로드에 적용하는 것이 바람직**합니다.

### 리더와 팔로워

리플리케이션된 파티션들에게는 리더와 팔로워로 역할이 나눠져 있습니다. 모든 읽기와 쓰기는 리더를 통해서만 가능합니다. 프로듀서는 모든 리플리케이션에 메시지를 보내는 것이 아니라 리더에게만 메시지를 전송하며 컨슈머도 오직 리더로부터 메시지를 가져옵니다.

팔로워들은 파티션의 리더가 새로운 메시지를 받았는지 확인하고, 새로운 메시지가 있다면 해당 메시지를 리더로부터 복제합니다.

### ISR(InSyncReplica)

리더와 팔로워는 ISR이라는 논리적 그룹으로 묶여 있습니다. 그 이유는 기본적으로 해당 그룹 안에 속한 팔로워들만이 새로운 리더의 자격을 가질 수 있기 때문입니다. 다시 말해, ISR 그룹에 속하지 못한 팔로워는 새로운 리더의 자격을 가질 수 없습니다. ISR 내의 팔로워들은 리더와의 데이터 일치를 유지하기 위해 지속적으로 리더의 데이터를 따라가게 되고, 리더는 ISR 내 모든 팔로워가 메시지를 받을 때까지 기다립니다.

ISR 내에서 모든 팔로워의 복제가 완료되면, 리더는 내부적으로 커밋되었다는 표시를 하게 됩니다. 마지막 커밋 오프셋 위치는 **하이워터마크**라고 부릅니다. 이렇게 커밋된 메시지만 컨슈머가 읽어갈 수 있습니다. 카프카에서 커밋되지 않은 메시지를 컨슈머가 읽을 수 없게 하는 이유는 메시지의 일관성을 유지하기 위해서 입니다.

로컬 디스크의 **replication-offset-checkpoin**t라는 파일에 마지막 커밋 오프셋 위치를 저장합니다. 만약 특정 토픽 또는 파티션에 복제가 되지 않거나 문제가 있다고 판단되는 경우, replication-offset-checkpoint 파일의 내용을 확인하고 리플리케이션되고 있는 다른 브로커와 비교해 살펴보면, 어떤 브로커, 토픽, 파티션에 문제가 있는지 파악할 수 있습니다.

### 컨트롤러

**컨트롤러**는 리플리케이션에서 리더 선출 작업을 수행합니다. 카프카 클러스터 중 하나의 브로커가 컨트롤러 역할을 하게 되며, 파티션의 ISR 리스트 중에서 리더를 선출합니다. 리더를 선출하기 위한 ISR 리스트 정보는 안전한 저장소에 보관되어 있어야 하는데, 가용성 보장을 위해 주키퍼에 저장되어 있습니다.

### 프로듀서

#### 파티셔너

**프로듀서**는 토픽으로 메시지를 보낼 때 해당 토픽의 어느 파티션으로 메시지를 보내야 할지를 결정해야하는데, 이때 사용하는 것이 바로 파티셔너입니다.

**라운드 로빈 전략**

라운드 로빈 전략은 각 파티션에 하나씩 할당됩니다. 파티셔너를 거친 후의 레코드들은 배치 처리를 위해 프로듀서의 버퍼 메모리 영역에서 잠시 대기한 후 카프카로 전송됩니다. 이러한 배치 처리를 위해 잠시 메시지들을 대기하는 과정에서 라운드 로빈 전략은 효율을 떨어뜨릴 수 있습니다.

**스티키 파티셔닝 전략**

**스티키 파티셔닝**이란 하나의 파티션에 레코드 수를 먼저 채워서 카프카로 빠르게 배치 전송하는 전략을 말합니다. 이 과정을 통해 라운드 로빈 전략에서 배치 전송을 위한 필요 레코드 수를 채우지 못해 카프카로 배치 전송하지 못했던 것과 달리 효율적으로 배치 전송 작업을 수행할 수 있습니다. 카프카로 전송하는 메시지의 순서가 그다지 중요하지 않은 경우라면 스티키 파티셔닝 전략을 적용하기를 권장합니다.

### 컨슈머

#### 그룹 코디네이터

컨슈머들은 하나의 컨슈머 그룹의 구성원으로 속합니다. 컨슈머 그룹에서 각 컨슈머들에게 작업을 균등하게 분해하는 동작을 **컨슈머 리밸런싱**이라고 부릅니다. 간혹 액티브/스탠바이 개념으로 추가 컨슈머가 더 있으면 좋을 것이라고 생각할 수도 있지만, 컨슈머 그룹내에서 리밸런싱 동작을 통해 장애가 발생한 컨슈머의 역할을 동일한 그룹에 있는 다른 컨슈머가 그 역할을 대신 수행하므로 굳이 장애 대비를 위한 컨슈머 리소스를 할당하지 않아도 됩니다.

안정적인 컨슈머 그룹 관리를 위해 별도의 코디네이터가 존재하는데, 이를 카프카에서는 **그룹 코디네이터**라고 부릅니다. 파티션 또는 그룹의 멤버에 변화가 생기면, 작업을 균등하게 재분배하기 위해 컨슈머 리밸런싱 동작이 발생합니다. 그룹 코디네이터는 각 컨슈머 그룹별로 존재하며, 이러한 그룹 코디네이터는 카프카 클러스터 내의 브로커 중 하나에 위치합니다.

#### 스태틱 멤버십

때로는, 하드웨어 점검이나 소프트웨어 업데이트 등의 이유로 관리자는 컨슈머 그룹 내의 컨슈머들을 한나씩 순차적으로 재시작하고 싶은 경우가 있을 것입니다. 하지만 **하트비트 주기(heartbeat.interval.ms)**, **세션 타임아웃(session.timeout.ms)** 등의 설정으로 인해 하나의 컨슈머가 재시작될 때마다 전체 리밸런싱이 일어나며, 리밸런싱 작업이 일어나는 동안 컨슈머들은 일시 중지하므로 매우 번거로운 일이 아닐 수 없습니다.

일반적인 컨슈머 그룹 동작에서는 각 컨슈머를 식별하기 위해 엔티티 ID를 부여하게 됩니다. 이렇게 생성된 ID들은 컨슈머 그룹 내에서 임시로 사용되는 것입니다. 따라서 컨슈머의 설정 변경이나 소프트웨어 업데이트로 인해 컨슈머가 재시작되면, 컨슈머 그룹 내의 동일한 컨슈머임에도 새로운 컨슈머로 인식해 새로운 엔티티ID가 부여되고 이로 인해 컨슈머 그룹의 리밸런싱이 발생하는 것입니다.

이러한 불필요한 리밸런싱을 방어하기 위해 카프카 2.3버전부터 스태틱 멤버십이라는 개념을 도입했습니다. **스태틱 멤버십**이란 컨슈머 그룹 내에서 컨슈머가 재시작 등으로 그룹에서 나갔다가 다시 합류하더라도 리밸런싱이 일어나지 않게 합니다. 즉, 컨슈머마다 인식할 수 있는 ID를 적용하여 다시 합류하더라도 그룹 코디네이터가 기존 구성원임을 인식할 수 있게 하는것입니다. 그 뿐만 아니라 스태틱 멤버십 기능이 적용된 컨슈머는 그룹에서 떠날 때 그룹 코디네이터에게 알리지 않으므로 불필요한 리밸런식도 발생하지 않습니다.

기본적으로 컨슈머 그룹에서 컨슈머가 떠날 때 리밸런싱이 일어나는데, 스새틱 멤버십이 적용된 컨슈머는 그룹에서 떠날 때 그룹 코디네이터에게 알리지 않으므로 여기서 한 번의 리밸런싱을 피할 수 있습니다. 그리고 해당 컨슈머가 다시 합류할 때 그룹 코디네이터가 컨슈머의 ID를 확인하고 리밸런싱이 일어나는데, 이때도 기존 구성원임을 인지하므로 리밸런싱은 발생하지 않습니다. 이와 같이 스태틱 멤버십을 적용하면 총 두 번의 리밸런싱을 회피할 수 있습니다.

만약 스태택 멤버십 기능을 적용한다면, session.timeout.ms를 기본값보다는 큰 값으로 저장해야 할것입니다. 예를 들어 컨슈머 재시작 시간이 총 2분 소요된다면, session.timeout.mx 값은 2분보다 큰 값으로 설정해야 불필요한 리밸런싱 동작을 사전에 방지할 수 있습니다.
